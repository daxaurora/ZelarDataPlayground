{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "piano-robin",
   "metadata": {},
   "source": [
    "This notebook creates a baseline model for predicting dementia from linguistic data.\n",
    "\n",
    "Data source: Ram Balasubramanium at Zelar Health.  \n",
    "Confirm: data originally from https://dementia.talkbank.org/access/English/Pitt.html\n",
    "\n",
    "Python library for parsing chat files:\n",
    "https://pylangacq.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pretty-breath",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from copy import deepcopy\n",
    "import re\n",
    "import pylangacq\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "choice-suffering",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "Extract data from chat transcript files into pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simplified-olympus",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_control = 'PittData/PittTranscripts/Control/cookie/'\n",
    "files_dementia = 'PittData/PittTranscripts/Dementia/cookie/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separate-forum",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count files in directories\n",
    "file_count_control = !ls $files_control | wc -l\n",
    "file_count_dementia = !ls $files_dementia| wc -l\n",
    "all_files_count = int(file_count_control[0]) + int(file_count_dementia[0])\n",
    "print('Control files:', file_count_control[0])\n",
    "print('Dementia files:', file_count_dementia[0])\n",
    "print('All files:', all_files_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acknowledged-wound",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data into chat reader\n",
    "raw_data = pylangacq.Reader.from_dir(files_control)\n",
    "raw_data.append(pylangacq.Reader.from_dir(files_dementia))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "champion-obligation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create index from filenames and check index structure\n",
    "idx = [i['Media'].split(',')[0] for i in raw_data.headers()]\n",
    "print('Index length:', len(idx))\n",
    "print('Are all index values unique?', len(idx) == len(set(idx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "first-calendar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set column names for features and output variables\n",
    "cols = ['Group', 'MMSE', 'INV_Interjections', 'Repeats']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "theoretical-confidence",
   "metadata": {},
   "source": [
    "#### Extract output variables\n",
    "* _Control/Dementia_: Set binary variable for control to 0 and any dementia diagnosis to 1\n",
    "* _MMSE_: Not all files have a recorded MMSE value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "natural-investigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine group values\n",
    "values = [i['Participants']['PAR']['group'] for i in raw_data.headers()]\n",
    "print('Unique group values:\\n', set(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vietnamese-spirit",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of occurences of blank group value:\", values.count(''))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "close-audience",
   "metadata": {},
   "source": [
    "Solution: If blank group value is assigned to Control, binary variable assignment matches original file designation.\n",
    "\n",
    "Optional further exploration: track down the file with the blank control value to confirm it was corrected assigned to the control group OR delete it from the raw dataset before extracting other values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exclusive-material",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set binary variable for Control=0 and Any Dementia Diagnosis =1\n",
    "group = [0 if i['Participants']['PAR']['group'] == 'Control' or i['Participants']['PAR']['group'] == ''\n",
    "         else 1\n",
    "         for i in raw_data.headers()]\n",
    "print('Dementia datapoints:', np.array(group).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-visibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MMSE was coded by transcribers in the 'education' key in each transcript's header\n",
    "MMSE = [int(i['Participants']['PAR']['education']) if i['Participants']['PAR']['education'] != ''\n",
    "        else None\n",
    "        for i in raw_data.headers()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranking-bobby",
   "metadata": {},
   "source": [
    "#### Extract feature variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apparent-dragon",
   "metadata": {},
   "outputs": [],
   "source": [
    "INV = [len(i) for i in raw_data.utterances(participants=\"INV\", by_files=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "magnetic-china",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract number of word or phrase repetitions\n",
    "repeat_word = '\\[/\\]'\n",
    "repeat_phrase = '\\[//\\]'\n",
    "\n",
    "reps = []\n",
    "for file in raw_data.utterances(by_files=True):\n",
    "    # Collect each file's utterances into a single string to search using regular expressions\n",
    "    utts_list = []\n",
    "    for utterance in file:\n",
    "        utts_list.append(utterance.tiers.get('PAR', ''))\n",
    "    utts = \"\".join(utts_list)\n",
    "    # add each file's number of repeated words and phrases to the variable\n",
    "    reps.append(len(re.findall(repeat_word, utts)) + \\\n",
    "                len(re.findall(repeat_phrase, utts)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worldwide-helmet",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(list(zip(grp_c + grp_d, \n",
    "                             MMSE_c + MMSE_d,\n",
    "                             INV_c + INV_d,\n",
    "                             reps_c + reps_d\n",
    "                             )),\n",
    "                    columns=cols, \n",
    "                    index=idx_c + idx_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mediterranean-south",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(list(zip(group, \n",
    "                             MMSE,\n",
    "                             INV,\n",
    "                             reps\n",
    "                             )),\n",
    "                    columns=cols, \n",
    "                    index=idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wired-premium",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check combined index structure\n",
    "print('Index length:', data.index.size)\n",
    "print('Are all index values unique?', len(data.index) == len(set(data.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afraid-spanish",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name index and dataframe\n",
    "data.index.name = 'Filename'\n",
    "data.name = 'Dementia Study - Cookie Theft Data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pursuant-vancouver",
   "metadata": {},
   "source": [
    "## Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comic-poetry",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Rows:\", data.shape[0], \"Columns:\", data.shape[1])\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perfect-hungarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Index data type:', data.index.dtype)\n",
    "data.dtypes\n",
    "# Note: MMSE is interpreted by Python as float bcause of missing MMSE data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "early-devil",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monetary-trainer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Control group Summary statistics\n",
    "data[data.Group==0].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "touched-steps",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dementia group Summary statistics\n",
    "data[data.Group==1].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preceding-huntington",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review missing values\n",
    "print('{0:<20} {1:^30}'.format('Samples Total', data.shape[0]))\n",
    "print()\n",
    "print('{0:<20} {1:^30}'.format('Variable', 'Samples with Missing Data'))\n",
    "print()\n",
    "# Data Index\n",
    "print('{0:<20} {1:^30}'.format(data.index.name, pd.isna(data.index).sum()))\n",
    "# Each column\n",
    "for i in range(len(cols)):\n",
    "    print('{0:<20} {1:^30}'.format(cols[i], pd.isna(data[cols[i]]).sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "short-crazy",
   "metadata": {},
   "source": [
    "Are variables normally distributed?  **No**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "owned-enlargement",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (16,4)) \n",
    "for i in range(len(cols)):\n",
    "    ax = fig.add_subplot(1, 4, i+1)\n",
    "    ax.hist(data[cols[i]].dropna(), color='mediumvioletred') \n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    ax.spines[\"left\"].set_visible(False)\n",
    "    ax.yaxis.set_ticks_position('none')\n",
    "    ax.set_yticklabels('')\n",
    "    ax.set_xlabel(cols[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attempted-tournament",
   "metadata": {},
   "source": [
    "Prepare data for creating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fossil-reform",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle data\n",
    "data = data.sample(frac=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precious-attempt",
   "metadata": {},
   "source": [
    "First model created with only one input feature: the number of interjections by the Investigator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mexican-woman",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data[\"INV_Interjections\"],\n",
    "                                                    data['Group'], \n",
    "                                                    test_size = 0.3,\n",
    "                                                    stratify = data['Group'], \n",
    "                                                    random_state = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reported-jefferson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm equal control vs. dementia split in train vs. test sets\n",
    "print('Full group % dementia:', round(data['Group'].mean(), 4))\n",
    "print('Training set % dementia:', round(y_train.mean(), 4))\n",
    "print('Test set % dementia:', round(y_test.mean(), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contained-central",
   "metadata": {},
   "source": [
    "TO DO:\n",
    "Set up for cross-validation within training data.  Also set random seed for the shuffle in addition to the random state already in the train/test split."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continental-talent",
   "metadata": {},
   "source": [
    "### Baseline models\n",
    "\n",
    "For comparison, baseline models created from the dataset used for ADReSS challenge for the 2020 Interspeech Conference reached 75% accuracy and f1 scores using a different subset of linguistic data from the same raw dataset.\\*\n",
    "\n",
    "The dataset used for the ADreSS challenge was an age and gender-matched subset of the full Pitt dataset, and included spontaenous speech. The model used 34 linguistic features extracted from the raw dataset, including duration, total utterances, MLU (mean length of utterance), type-token ratio, open-closed class word ratio, and percentages of 9 parts of speech. \n",
    "\n",
    "The baseline model created in this notebook uses the portion of the Pitt dataset in which participants are asked to describe the cookie theft picture commonly used in aphasia testing and uses only one feature, the number of interjections by the interviewer.\n",
    "\n",
    "It's also worth noting that it's unknown if the interviewer had knowledge of any diagnoses of the participants, and this knowledge could influence the number of their injections (i.e., whether they perceived a participant would need assistance given their diagnosis).  For this reason it would be useful to try at least one other potentially less biased feature for creating a baseline model.  \n",
    "\n",
    "\n",
    "\\* Luz S, Haider F, de la Fuente S, Fromm D, MacWhinney B. August 2020. *Alzheimerâ€™s Dementia Recognition through Spontaneous Speech: The ADReSS Challenge.* https://arxiv.org/abs/2004.06833v3  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stone-slovenia",
   "metadata": {},
   "source": [
    "#### Logistic Regression prediction of control vs. dementia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passive-carroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "logm= LogisticRegression()\n",
    "log_baseline = logm.fit(pd.DataFrame(X_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seventh-receiver",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assess fit of model\n",
    "print('Accuracy of baseline model is:')\n",
    "print(round(log_baseline.score(pd.DataFrame(X_test), y_test), 2))\n",
    "print('Area under the ROC curve is:')\n",
    "print(round(roc_auc_score(y_test, log_baseline.predict_proba(pd.DataFrame(X_test))[:, 1]), 2))\n",
    "print('F1 score is:')\n",
    "print(round(f1_score(y_test, log_baseline.predict(pd.DataFrame(X_test))), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "other-heath",
   "metadata": {},
   "source": [
    "#### Prediction of MMSE\n",
    "\n",
    "TO COME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerical-brake",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
