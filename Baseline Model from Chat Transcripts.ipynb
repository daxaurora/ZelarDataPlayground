{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "piano-robin",
   "metadata": {},
   "source": [
    "This notebook creates a baseline model for predicting dementia from linguistic data.\n",
    "\n",
    "Data source: Ram Balasubramanium at Zelar Health.  \n",
    "? originally from https://dementia.talkbank.org/access/English/Pitt.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "pretty-breath",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pylangacq\n",
    "from copy import deepcopy\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "choice-suffering",
   "metadata": {},
   "source": [
    "### Set Up Data\n",
    "Extract data from chat transcript files into pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "simplified-olympus",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_control = 'PittData/PittTranscripts/Control/cookie/'\n",
    "files_dementia = 'PittData/PittTranscripts/Dementia/cookie/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "married-detection",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = pylangacq.Reader.from_dir(files_control)\n",
    "d = pylangacq.Reader.from_dir(files_dementia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "voluntary-binary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filenames become DataFrame index\n",
    "idx_c = [i['Media'].split(',')[0] for i in c.headers()]\n",
    "idx_d = [i['Media'].split(',')[0] for i in d.headers()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "automatic-minutes",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index length - control: 243\n",
      "Index length - dementia: 309\n",
      "Are all index values in control group unique? True\n",
      "Are all index values in dementia group unique? True\n"
     ]
    }
   ],
   "source": [
    "# Check index structure\n",
    "print('Index length - control:', len(idx_c))\n",
    "print('Index length - dementia:', len(idx_d))\n",
    "print('Are all index values in control group unique?', len(idx_c) == len(set(idx_c)))\n",
    "print('Are all index values in dementia group unique?', len(idx_d) == len(set(idx_d)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "first-calendar",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Group', 'MMSE', 'INV_Interjections', 'Repeats']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "juvenile-usage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set binary variable for control group vs. dementia group\n",
    "grp_c = [0] * len(idx_c)\n",
    "grp_d = [1] * len(idx_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "declared-oakland",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MMSE was coded by transcribers in the 'education' key in each transcript's header\n",
    "MMSE_c = [int(i['Participants']['PAR']['education']) if i['Participants']['PAR']['education'] != ''\n",
    "                else 'NaN'\n",
    "                for i in c.headers()]\n",
    "MMSE_d = [int(i['Participants']['PAR']['education']) if i['Participants']['PAR']['education'] != ''\n",
    "                else 'NaN'\n",
    "                for i in d.headers()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "empty-walter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract number of interjections by investigator per interview\n",
    "INV_c = [len(i) for i in c.utterances(participants=\"INV\", by_files=True)]\n",
    "INV_d = [len(i) for i in d.utterances(participants=\"INV\", by_files=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "entitled-dressing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract number of word or phrase repetitions\n",
    "repeat_word = '\\[/\\]'\n",
    "repeat_phrase = '\\[//\\]'\n",
    "def get_repeats(chat_files):\n",
    "    \"\"\"Input: List of files from chat transcripts.\n",
    "       Ouput: List of the sum of repeated words and phrases in each file.\"\"\"\n",
    "    reps = []\n",
    "    for file in chat_files:\n",
    "        # Collect relevant parts of each utterance into a single string before searching\n",
    "        utts_list = []\n",
    "        for utterance in file:\n",
    "            utts_list.append(utterance.tiers.get('PAR', ''))\n",
    "            utts = \"\".join(utts_list)\n",
    "            reps_file = len(re.findall(repeat_word, utts)) + \\\n",
    "                      len(re.findall(repeat_phrase, utts))\n",
    "        reps.append(reps_file)\n",
    "    return reps\n",
    "\n",
    "reps_c = get_repeats(c.utterances(by_files=True))\n",
    "reps_d = get_repeats(d.utterances(by_files=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "worldwide-helmet",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(list(zip(grp_c + grp_d, \n",
    "                             MMSE_c + MMSE_d,\n",
    "                             INV_c + INV_d,\n",
    "                             reps_c + reps_d\n",
    "                             )),\n",
    "                    columns=cols, \n",
    "                    index=idx_c + idx_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "wired-premium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index length: 552\n",
      "Are all index values unique? True\n"
     ]
    }
   ],
   "source": [
    "# Check combined index structure\n",
    "print('Index length:', data.index.size)\n",
    "print('Are all index values unique?', len(data.index) == len(set(data.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "generic-customs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert MMSE to numeric from default conversion to object\n",
    "data['MMSE'] = pd.to_numeric(data['MMSE'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "perfect-hungarian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Group                  int64\n",
       "MMSE                 float64\n",
       "INV_Interjections      int64\n",
       "Repeats                int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "monetary-trainer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group</th>\n",
       "      <th>MMSE</th>\n",
       "      <th>INV_Interjections</th>\n",
       "      <th>Repeats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>243.0</td>\n",
       "      <td>181.000000</td>\n",
       "      <td>243.000000</td>\n",
       "      <td>243.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>29.127072</td>\n",
       "      <td>3.193416</td>\n",
       "      <td>1.934156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.110749</td>\n",
       "      <td>1.865198</td>\n",
       "      <td>2.222115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Group        MMSE  INV_Interjections     Repeats\n",
       "count  243.0  181.000000         243.000000  243.000000\n",
       "mean     0.0   29.127072           3.193416    1.934156\n",
       "std      0.0    1.110749           1.865198    2.222115\n",
       "min      0.0   24.000000           0.000000    0.000000\n",
       "25%      0.0   29.000000           2.000000    0.000000\n",
       "50%      0.0   29.000000           3.000000    1.000000\n",
       "75%      0.0   30.000000           4.000000    3.000000\n",
       "max      0.0   30.000000           9.000000   17.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Control group Summary statistics\n",
    "data[data['Group']==0].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "touched-steps",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group</th>\n",
       "      <th>MMSE</th>\n",
       "      <th>INV_Interjections</th>\n",
       "      <th>Repeats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>309.0</td>\n",
       "      <td>277.000000</td>\n",
       "      <td>309.000000</td>\n",
       "      <td>309.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.0</td>\n",
       "      <td>19.779783</td>\n",
       "      <td>5.741100</td>\n",
       "      <td>3.631068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.668872</td>\n",
       "      <td>4.435427</td>\n",
       "      <td>4.197998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.0</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>29.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Group        MMSE  INV_Interjections     Repeats\n",
       "count  309.0  277.000000         309.000000  309.000000\n",
       "mean     1.0   19.779783           5.741100    3.631068\n",
       "std      0.0    5.668872           4.435427    4.197998\n",
       "min      1.0    1.000000           0.000000    0.000000\n",
       "25%      1.0   16.000000           3.000000    1.000000\n",
       "50%      1.0   20.000000           5.000000    2.000000\n",
       "75%      1.0   24.000000           7.000000    5.000000\n",
       "max      1.0   30.000000          49.000000   29.000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dementia group Summary statistics\n",
    "data[data['Group']==1].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changing-permission",
   "metadata": {},
   "source": [
    "TO DO: Look for missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attempted-tournament",
   "metadata": {},
   "source": [
    "Prepare data for creating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fossil-reform",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle data\n",
    "data = data.sample(frac=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precious-attempt",
   "metadata": {},
   "source": [
    "First model created with only one input feature: the number of interjections by the Investigator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "mexican-woman",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data[\"INV_Interjections\"],\n",
    "                                                    data['Group'], \n",
    "                                                    test_size = 0.3,\n",
    "                                                    stratify = data['Group'], \n",
    "                                                    random_state = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "reported-jefferson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full group % dementia: 0.5598\n",
      "Training set % dementia: 0.5596\n",
      "Test set % dementia: 0.5602\n"
     ]
    }
   ],
   "source": [
    "# confirm equal control vs. dementia split in train vs. test sets\n",
    "print('Full group % dementia:', round(data['Group'].mean(), 4))\n",
    "print('Training set % dementia:', round(y_train.mean(), 4))\n",
    "print('Test set % dementia:', round(y_test.mean(), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contained-central",
   "metadata": {},
   "source": [
    "TO DO:\n",
    "Set up for cross-validation within training data.  Also set random seed for the shuffle in addition to the random state already in the train/test split."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continental-talent",
   "metadata": {},
   "source": [
    "### Baseline models\n",
    "\n",
    "For comparison, baseline models created from the dataset used for ADReSS challenge for the 2020 Interspeech Conference reached 75% accuracy and f1 scores using a different subset of linguistic data from the same raw dataset.\\*\n",
    "\n",
    "The dataset used for the ADreSS challenge was an age and gender-matched subset of the full Pitt dataset, and included spontaenous speech. The model used 34 linguistic features extracted from the raw dataset, including duration, total utterances, MLU (mean length of utterance), type-token ratio, open-closed class word ratio, and percentages of 9 parts of speech. \n",
    "\n",
    "The baseline model created in this notebook uses the portion of the Pitt dataset in which participants are asked to describe the cookie theft picture commonly used in aphasia testing and uses only one feature, the number of interjections by the interviewer.\n",
    "\n",
    "It's also worth noting that it's unknown if the interviewer had knowledge of any diagnoses of the participants, and this knowledge could influence the number of their injections (i.e., whether they perceived a participant would need assistance given their diagnosis).  For this reason it would be useful to try at least one other potentially less biased feature for creating a baseline model.  \n",
    "\n",
    "\n",
    "\\* Luz S, Haider F, de la Fuente S, Fromm D, MacWhinney B. August 2020. *Alzheimer’s Dementia Recognition through Spontaneous Speech: The ADReSS Challenge.* https://arxiv.org/abs/2004.06833v3  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stone-slovenia",
   "metadata": {},
   "source": [
    "#### Logistic Regression prediction of control vs. dementia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "passive-carroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "logm= LogisticRegression()\n",
    "log_baseline = logm.fit(pd.DataFrame(X_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "seventh-receiver",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of baseline model is:\n",
      "0.66\n",
      "Area under the ROC curve is:\n",
      "0.73\n",
      "F1 score is:\n",
      "0.7\n"
     ]
    }
   ],
   "source": [
    "# Assess fit of model\n",
    "print('Accuracy of baseline model is:')\n",
    "print(round(log_baseline.score(pd.DataFrame(X_test), y_test), 2))\n",
    "print('Area under the ROC curve is:')\n",
    "print(round(roc_auc_score(y_test, log_baseline.predict_proba(pd.DataFrame(X_test))[:, 1]), 2))\n",
    "print('F1 score is:')\n",
    "print(round(f1_score(y_test, log_baseline.predict(pd.DataFrame(X_test))), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "other-heath",
   "metadata": {},
   "source": [
    "#### Prediction of MMSE\n",
    "\n",
    "TO COME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerical-brake",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
